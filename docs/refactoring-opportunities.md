# Responses API Refactoring Opportunities

## Overview

This document identifies optimization and refactoring opportunities for the Responses and Conversations API implementation. The current code is functional and working well, but these refactorings will improve maintainability, testability, and performance.

## Priority Legend

- 游댮 **Critical** - High impact on maintainability, should be done soon
- 游리 **Important** - Significant improvement, do when convenient
- 游릭 **Nice to have** - Polish and optimization, lower priority

---

## High-Impact Refactorings

### 游댮 1. Break Up `create_response_stream` Function

**Location:** `src/web/responses.rs:612-1434`

**Problem:** Single 800+ line function doing too much - validation, context building, streaming setup, SSE event generation, channel management, and error handling.

**Solution:** Extract into separate phases with clear responsibilities.

```rust
// Current: Everything in one giant function
async fn create_response_stream(...) -> Result<Sse<...>> {
    // 800+ lines of mixed concerns
}

// Better: Separate concerns
async fn create_response_stream(...) -> Result<Sse<...>> {
    let context = prepare_request_context(state, user, body).await?;
    let (channels, tasks) = setup_streaming_infrastructure(context).await?;
    Ok(create_sse_event_stream(context, channels))
}

struct RequestContext {
    response: Response,
    conversation: Conversation,
    user_key: SecretKey,
    assistant_message_id: Uuid,
    decrypted_metadata: Option<Value>,
    prompt_messages: Vec<Value>,
    total_prompt_tokens: usize,
}

async fn prepare_request_context(
    state: &Arc<AppState>,
    user: &User,
    body: &ResponsesCreateRequest,
) -> Result<RequestContext, ApiError> {
    // Validation
    // User key retrieval
    // Message normalization
    // Context building
    // Billing check
    // Initial persistence
}

struct StreamingChannels {
    tx_storage: mpsc::Sender<StorageMessage>,
    rx_client: mpsc::Receiver<StorageMessage>,
}

async fn setup_streaming_infrastructure(
    context: &RequestContext,
    state: Arc<AppState>,
) -> Result<(StreamingChannels, JoinHandle<()>), ApiError> {
    // Create channels
    // Spawn storage task
    // Spawn upstream processor task
    // Return channels and task handles
}

fn create_sse_event_stream(
    context: RequestContext,
    channels: StreamingChannels,
    state: Arc<AppState>,
) -> Sse<impl Stream<...>> {
    // Build SSE stream
    // Emit events
    // Handle completion
}
```

**Benefits:**
- Each function has a single, clear responsibility
- Much easier to test individual phases
- Reduced cognitive load when reading code
- Easier to add new features to specific phases

---

### 游댮 2. Extract SSE Event Builder

**Location:** `src/web/responses.rs:1020-1426` (repeated ~10 times)

**Problem:** Nearly identical encryption + serialization + error handling repeated for every event type (~300 lines of duplication).

**Solution:** Create a reusable event emitter struct.

```rust
struct SseEventEmitter<'a> {
    state: &'a AppState,
    session_id: Uuid,
    sequence_number: i32,
}

impl SseEventEmitter<'_> {
    fn new(state: &AppState, session_id: Uuid, initial_sequence: i32) -> Self {
        Self {
            state,
            session_id,
            sequence_number: initial_sequence,
        }
    }

    async fn emit<T: Serialize>(&mut self, event_type: &str, data: &T) -> Event {
        self.sequence_number += 1;

        match serde_json::to_value(data) {
            Ok(json) => {
                match encrypt_event(self.state, &self.session_id, event_type, &json).await {
                    Ok(event) => {
                        trace!("Yielding {} event (seq: {})", event_type, self.sequence_number);
                        event
                    }
                    Err(e) => {
                        error!("Failed to encrypt {} event: {:?}", event_type, e);
                        Event::default().event("error").data("encryption_failed")
                    }
                }
            }
            Err(e) => {
                error!("Failed to serialize {}: {:?}", event_type, e);
                Event::default().event("error").data("serialization_failed")
            }
        }
    }

    fn get_sequence_number(&self) -> i32 {
        self.sequence_number
    }
}

// Usage in stream:
let mut emitter = SseEventEmitter::new(&state, session_id, 0);

yield Ok(emitter.emit("response.created", &created_event).await);
yield Ok(emitter.emit("response.in_progress", &in_progress_event).await);
yield Ok(emitter.emit("response.output_item.added", &output_item_added_event).await);
// etc.
```

**Benefits:**
- Eliminates ~300 lines of duplication
- Centralized error handling for all events
- Automatic sequence number management
- Easy to add logging/metrics to all events

---

### 游댮 3. Extract Upstream Stream Processor

**Location:** `src/web/responses.rs:815-974`

**Problem:** Complex SSE parsing, buffer management, and channel broadcasting all inline in a spawned task.

**Solution:** Create a dedicated struct to handle upstream stream processing.

```rust
struct UpstreamStreamProcessor {
    buffer: String,
    storage_tx: mpsc::Sender<StorageMessage>,
    client_tx: mpsc::Sender<StorageMessage>,
    message_id: Uuid,
    finish_reason: Option<String>,
}

impl UpstreamStreamProcessor {
    fn new(
        storage_tx: mpsc::Sender<StorageMessage>,
        client_tx: mpsc::Sender<StorageMessage>,
        message_id: Uuid,
    ) -> Self {
        Self {
            buffer: String::with_capacity(8192),
            storage_tx,
            client_tx,
            message_id,
            finish_reason: None,
        }
    }

    async fn process_chunk(&mut self, bytes: Bytes) -> Result<(), Box<dyn std::error::Error>> {
        self.buffer.push_str(&String::from_utf8_lossy(&bytes));

        while let Some(frame) = self.extract_sse_frame() {
            self.handle_sse_frame(&frame).await?;
        }

        Ok(())
    }

    fn extract_sse_frame(&mut self) -> Option<String> {
        if let Some(pos) = self.buffer.find("\n\n") {
            let frame = self.buffer[..pos].to_string();
            self.buffer = self.buffer[pos + 2..].to_string();

            if frame.trim().is_empty() {
                return None;
            }

            Some(frame)
        } else {
            None
        }
    }

    async fn handle_sse_frame(&mut self, frame: &str) -> Result<(), Box<dyn std::error::Error>> {
        // Skip non-data frames
        if !frame.starts_with("data: ") {
            return Ok(());
        }

        let data = frame.strip_prefix("data: ").unwrap().trim();

        if data == "[DONE]" {
            self.send_completion().await?;
            return Ok(());
        }

        let json_data: Value = serde_json::from_str(data)?;

        // Extract content delta
        if let Some(content) = json_data["choices"][0]["delta"]["content"].as_str() {
            self.send_content_delta(content).await?;
        }

        // Extract usage
        if let Some(usage) = json_data.get("usage") {
            self.send_usage(usage).await?;
        }

        // Extract finish reason
        if let Some(finish_reason) = json_data["choices"][0]["finish_reason"].as_str() {
            self.finish_reason = Some(finish_reason.to_string());
        }

        Ok(())
    }

    async fn send_content_delta(&self, content: &str) -> Result<(), Box<dyn std::error::Error>> {
        let msg = StorageMessage::ContentDelta(content.to_string());
        self.storage_tx.send(msg.clone()).await?;
        self.client_tx.send(msg).await?;
        Ok(())
    }

    async fn send_usage(&self, usage: &Value) -> Result<(), Box<dyn std::error::Error>> {
        let prompt_tokens = usage["prompt_tokens"].as_i64().unwrap_or(0) as i32;
        let completion_tokens = usage["completion_tokens"].as_i64().unwrap_or(0) as i32;

        let msg = StorageMessage::Usage {
            prompt_tokens,
            completion_tokens,
        };
        self.storage_tx.send(msg.clone()).await?;
        self.client_tx.send(msg).await?;
        Ok(())
    }

    async fn send_completion(&self) -> Result<(), Box<dyn std::error::Error>> {
        let msg = StorageMessage::Done {
            finish_reason: self.finish_reason.clone().unwrap_or_else(|| "stop".to_string()),
            message_id: self.message_id,
        };
        self.storage_tx.send(msg.clone()).await?;
        self.client_tx.send(msg).await?;
        Ok(())
    }
}

// Usage:
tokio::spawn(async move {
    let mut processor = UpstreamStreamProcessor::new(tx_storage, tx_client, message_id);

    loop {
        tokio::select! {
            Ok(cancelled_id) = cancel_rx.recv() => {
                if cancelled_id == response_uuid {
                    let _ = processor.send_cancellation().await;
                    break;
                }
            }
            chunk_result = body_stream.next() => {
                let Some(Ok(bytes)) = chunk_result else {
                    break;
                };
                if let Err(e) = processor.process_chunk(bytes).await {
                    error!("Error processing chunk: {:?}", e);
                    break;
                }
            }
        }
    }
});
```

**Benefits:**
- Encapsulates SSE parsing logic
- Testable in isolation
- Clear error handling boundaries
- Buffer management optimization opportunities

---

### 游댮 4. Centralize Message Content Conversions

**Location:** Scattered across `src/web/responses.rs` and `src/web/conversations.rs`

**Problem:** Message content conversion logic appears in multiple places with slight variations.

**Solution:** Create a centralized conversion service.

```rust
/// Centralized message content conversion utilities
pub struct MessageContentConverter;

impl MessageContentConverter {
    /// Normalize any input format to standard MessageInput array
    pub fn normalize_input(input: InputMessage) -> Vec<MessageInput> {
        match input {
            InputMessage::String(s) => {
                vec![MessageInput {
                    role: "user".to_string(),
                    content: MessageContent::Parts(vec![MessageContentPart::InputText { text: s }]),
                }]
            }
            InputMessage::Messages(mut messages) => {
                for msg in &mut messages {
                    msg.content = Self::normalize_content(msg.content.clone());
                }
                messages
            }
        }
    }

    /// Normalize MessageContent to always use Parts format
    pub fn normalize_content(content: MessageContent) -> MessageContent {
        match content {
            MessageContent::Text(text) => {
                MessageContent::Parts(vec![MessageContentPart::InputText { text }])
            }
            MessageContent::Parts(parts) => MessageContent::Parts(parts),
        }
    }

    /// Convert MessageContent to OpenAI API format for chat completions
    pub fn to_openai_format(content: &MessageContent) -> Value {
        match content {
            MessageContent::Text(text) => json!(text),
            MessageContent::Parts(parts) => {
                let openai_parts: Vec<Value> = parts
                    .iter()
                    .map(Self::content_part_to_openai)
                    .collect();
                json!(openai_parts)
            }
        }
    }

    /// Convert a single MessageContentPart to OpenAI format
    fn content_part_to_openai(part: &MessageContentPart) -> Value {
        match part {
            MessageContentPart::Text { text } | MessageContentPart::InputText { text } => {
                json!({
                    "type": "text",
                    "text": text
                })
            }
            MessageContentPart::InputImage { image_url, detail, .. } => {
                let mut image_obj = json!({
                    "url": image_url.as_ref().unwrap_or(&"".to_string())
                });
                if let Some(d) = detail {
                    image_obj["detail"] = json!(d);
                }
                json!({
                    "type": "image_url",
                    "image_url": image_obj
                })
            }
            MessageContentPart::InputFile { filename, file_data } => {
                json!({
                    "type": "file",
                    "file": {
                        "filename": filename,
                        "file_data": file_data
                    }
                })
            }
        }
    }

    /// Convert MessageContent to ConversationContent array for API responses
    pub fn to_conversation_content(content: MessageContent, role: &str) -> Vec<ConversationContent> {
        match (content, role) {
            (MessageContent::Text(text), "user") => {
                vec![ConversationContent::InputText { text }]
            }
            (MessageContent::Text(text), "assistant") => {
                vec![ConversationContent::OutputText { text }]
            }
            (MessageContent::Parts(parts), role) => {
                parts.into_iter().map(|part| Self::content_part_to_conversation(part, role)).collect()
            }
            _ => vec![],
        }
    }

    fn content_part_to_conversation(part: MessageContentPart, role: &str) -> ConversationContent {
        match (part, role) {
            (MessageContentPart::Text { text } | MessageContentPart::InputText { text }, "user") => {
                ConversationContent::InputText { text }
            }
            (MessageContentPart::Text { text } | MessageContentPart::InputText { text }, "assistant") => {
                ConversationContent::OutputText { text }
            }
            (MessageContentPart::InputImage { image_url, .. }, _) => {
                ConversationContent::InputImage {
                    image_url: image_url.unwrap_or_else(|| "[No URL]".to_string()),
                }
            }
            (MessageContentPart::InputFile { filename, .. }, _) => {
                ConversationContent::InputFile { filename }
            }
            _ => ConversationContent::InputText { text: "".to_string() },
        }
    }

    /// Extract text content for token counting purposes only
    pub fn extract_text_for_token_counting(content: &MessageContent) -> String {
        match content {
            MessageContent::Text(text) => text.clone(),
            MessageContent::Parts(parts) => {
                parts
                    .iter()
                    .filter_map(|part| match part {
                        MessageContentPart::Text { text } => Some(text.clone()),
                        MessageContentPart::InputText { text } => Some(text.clone()),
                        MessageContentPart::InputImage { .. } => None,
                        MessageContentPart::InputFile { .. } => None,
                    })
                    .collect::<Vec<_>>()
                    .join(" ")
            }
        }
    }
}
```

**Benefits:**
- Single source of truth for conversions
- Easier to test conversion logic
- Consistent behavior across all endpoints
- Easy to extend with new content types

---

### 游리 5. Extract Decryption Helper with Type Safety

**Location:** Repeated in `src/web/conversations.rs` (lines 660-664, 815-820, 947-962)

**Problem:** Decryption + deserialization + error handling repeated throughout.

**Solution:** Create generic decryption helper.

```rust
/// Decrypt and deserialize encrypted content with type safety
pub async fn decrypt_content<T>(
    key: &SecretKey,
    encrypted: Option<&Vec<u8>>,
) -> Result<T, DecryptionError>
where
    T: DeserializeOwned,
{
    let encrypted = encrypted.ok_or(DecryptionError::NoContent)?;

    let decrypted_bytes = decrypt_with_key(key, encrypted)
        .map_err(|e| DecryptionError::DecryptionFailed(e.to_string()))?;

    serde_json::from_slice(&decrypted_bytes)
        .map_err(|e| DecryptionError::DeserializationFailed(e.to_string()))
}

/// Decrypt and deserialize encrypted content with fallback
pub async fn decrypt_content_or<T>(
    key: &SecretKey,
    encrypted: Option<&Vec<u8>>,
    fallback: T,
) -> T
where
    T: DeserializeOwned,
{
    decrypt_content(key, encrypted).await.unwrap_or(fallback)
}

/// Decrypt encrypted content as plain string
pub async fn decrypt_string(
    key: &SecretKey,
    encrypted: Option<&Vec<u8>>,
    fallback: &str,
) -> String {
    encrypted
        .and_then(|enc| decrypt_with_key(key, enc).ok())
        .map(|bytes| String::from_utf8_lossy(&bytes).to_string())
        .unwrap_or_else(|| fallback.to_string())
}

#[derive(Debug, thiserror::Error)]
pub enum DecryptionError {
    #[error("No content to decrypt")]
    NoContent,
    #[error("Decryption failed: {0}")]
    DecryptionFailed(String),
    #[error("Deserialization failed: {0}")]
    DeserializationFailed(String),
}

// Usage examples:

// For MessageContent (structured data):
let content: MessageContent = decrypt_content(&user_key, msg.content_enc.as_ref())
    .await
    .map_err(|e| {
        error!("Failed to decrypt message: {:?}", e);
        ApiError::InternalServerError
    })?;

// For plain text with fallback:
let content = decrypt_string(&user_key, msg.content_enc.as_ref(), "[Decryption failed]").await;

// For metadata with default:
let metadata: Value = decrypt_content_or(&user_key, conv.metadata_enc.as_ref(), json!({})).await;
```

**Benefits:**
- Type-safe decryption operations
- Centralized error handling
- Consistent error messages
- Easier to add metrics/logging

---

### 游댮 6. Storage Task Separation of Concerns

**Location:** `src/web/responses.rs:1485-1716`

**Problem:** Single 230-line function accumulating content, handling all completion states, persisting data, and publishing billing events.

**Solution:** Break into smaller, testable components.

```rust
/// Accumulates streaming content and metadata
struct ContentAccumulator {
    content: String,
    completion_tokens: i32,
    prompt_tokens: i32,
    finish_reason: Option<String>,
}

impl ContentAccumulator {
    fn new() -> Self {
        Self {
            content: String::with_capacity(4096),
            completion_tokens: 0,
            prompt_tokens: 0,
            finish_reason: None,
        }
    }

    fn handle_message(&mut self, msg: StorageMessage) -> AccumulatorState {
        match msg {
            StorageMessage::ContentDelta(delta) => {
                self.content.push_str(&delta);
                AccumulatorState::Continue
            }
            StorageMessage::Usage { prompt_tokens, completion_tokens } => {
                self.prompt_tokens = prompt_tokens;
                self.completion_tokens = completion_tokens;
                AccumulatorState::Continue
            }
            StorageMessage::Done { finish_reason, message_id } => {
                self.finish_reason = Some(finish_reason);
                AccumulatorState::Complete(CompleteData {
                    content: self.content.clone(),
                    completion_tokens: self.completion_tokens,
                    prompt_tokens: self.prompt_tokens,
                    finish_reason: self.finish_reason.clone().unwrap(),
                    message_id,
                })
            }
            StorageMessage::Cancelled => {
                AccumulatorState::Cancelled(PartialData {
                    content: self.content.clone(),
                    completion_tokens: self.completion_tokens,
                })
            }
            StorageMessage::Error(e) => {
                AccumulatorState::Failed(FailureData {
                    error: e,
                    partial_content: self.content.clone(),
                    completion_tokens: self.completion_tokens,
                })
            }
        }
    }
}

enum AccumulatorState {
    Continue,
    Complete(CompleteData),
    Cancelled(PartialData),
    Failed(FailureData),
}

struct CompleteData {
    content: String,
    completion_tokens: i32,
    prompt_tokens: i32,
    finish_reason: String,
    message_id: Uuid,
}

struct PartialData {
    content: String,
    completion_tokens: i32,
}

struct FailureData {
    error: String,
    partial_content: String,
    completion_tokens: i32,
}

/// Handles persistence of responses in various states
struct ResponsePersister {
    db: Arc<dyn crate::DBConnection + Send + Sync>,
    response_id: i64,
    message_id: Uuid,
    user_key: SecretKey,
}

impl ResponsePersister {
    fn new(
        db: Arc<dyn crate::DBConnection + Send + Sync>,
        response_id: i64,
        message_id: Uuid,
        user_key: SecretKey,
    ) -> Self {
        Self {
            db,
            response_id,
            message_id,
            user_key,
        }
    }

    async fn persist_completed(&self, data: CompleteData) -> Result<(), DBError> {
        // Fallback token counting if not provided
        let completion_tokens = if data.completion_tokens == 0 && !data.content.is_empty() {
            count_tokens(&data.content) as i32
        } else {
            data.completion_tokens
        };

        // Encrypt and store assistant message
        let content_enc = encrypt_with_key(&self.user_key, data.content.as_bytes()).await;

        self.db.update_assistant_message(
            self.message_id,
            Some(content_enc),
            completion_tokens,
            "completed".to_string(),
            Some(data.finish_reason),
        )?;

        // Update response status
        self.db.update_response_status(
            self.response_id,
            ResponseStatus::Completed,
            Some(Utc::now()),
            Some(data.prompt_tokens),
            Some(completion_tokens),
        )?;

        Ok(())
    }

    async fn persist_cancelled(&self, data: PartialData) -> Result<(), DBError> {
        // Update response status
        self.db.update_response_status(
            self.response_id,
            ResponseStatus::Cancelled,
            Some(Utc::now()),
            None,
            Some(data.completion_tokens),
        )?;

        // Update assistant message to incomplete status with partial content
        let content_enc = if !data.content.is_empty() {
            Some(encrypt_with_key(&self.user_key, data.content.as_bytes()).await)
        } else {
            None
        };

        self.db.update_assistant_message(
            self.message_id,
            content_enc,
            data.completion_tokens,
            "incomplete".to_string(),
            Some("cancelled".to_string()),
        )?;

        Ok(())
    }

    async fn persist_failed(&self, data: FailureData) -> Result<(), DBError> {
        // Update response status
        self.db.update_response_status(
            self.response_id,
            ResponseStatus::Failed,
            Some(Utc::now()),
            None,
            None,
        )?;

        // Update assistant message to incomplete status with partial content
        let content_enc = if !data.partial_content.is_empty() {
            Some(encrypt_with_key(&self.user_key, data.partial_content.as_bytes()).await)
        } else {
            None
        };

        self.db.update_assistant_message(
            self.message_id,
            content_enc,
            data.completion_tokens,
            "incomplete".to_string(),
            None,
        )?;

        Ok(())
    }
}

/// Publishes usage events for billing
struct BillingEventPublisher {
    sqs_publisher: Option<Arc<crate::sqs::SqsEventPublisher>>,
    user_uuid: Uuid,
}

impl BillingEventPublisher {
    async fn publish(&self, prompt_tokens: i32, completion_tokens: i32) {
        if prompt_tokens == 0 && completion_tokens == 0 {
            return;
        }

        let db_clone = self.db.clone();
        let sqs_pub = self.sqs_publisher.clone();
        let user_uuid = self.user_uuid;

        tokio::spawn(async move {
            // Calculate cost
            let input_cost = BigDecimal::from_str("0.0000053").unwrap()
                * BigDecimal::from(prompt_tokens);
            let output_cost = BigDecimal::from_str("0.0000053").unwrap()
                * BigDecimal::from(completion_tokens);
            let total_cost = input_cost + output_cost;

            info!(
                "Responses API usage for user {}: prompt={}, completion={}, total={}, cost={}",
                user_uuid, prompt_tokens, completion_tokens,
                prompt_tokens + completion_tokens, total_cost
            );

            // Store token usage
            let new_usage = NewTokenUsage::new(
                user_uuid,
                prompt_tokens,
                completion_tokens,
                total_cost.clone(),
            );

            if let Err(e) = db_clone.create_token_usage(new_usage) {
                error!("Failed to save token usage: {:?}", e);
            }

            // Publish to SQS
            if let Some(publisher) = sqs_pub {
                let event = UsageEvent {
                    event_id: Uuid::new_v4(),
                    user_id: user_uuid,
                    input_tokens: prompt_tokens,
                    output_tokens: completion_tokens,
                    estimated_cost: total_cost,
                    chat_time: Utc::now(),
                    is_api_request: false,
                    provider_name: String::new(),
                    model_name: String::new(),
                };

                match publisher.publish_event(event).await {
                    Ok(_) => debug!("Published usage event successfully"),
                    Err(e) => error!("Error publishing usage event: {e}"),
                }
            }
        });
    }
}

// Main storage task becomes simple orchestration:
async fn storage_task(
    mut rx: mpsc::Receiver<StorageMessage>,
    db: Arc<dyn crate::DBConnection + Send + Sync>,
    response_id: i64,
    _conversation_id: i64,
    user_key: secp256k1::SecretKey,
    user_uuid: Uuid,
    sqs_publisher: Option<Arc<crate::sqs::SqsEventPublisher>>,
    message_id: Uuid,
) {
    let mut accumulator = ContentAccumulator::new();
    let persister = ResponsePersister::new(db.clone(), response_id, message_id, user_key);
    let billing = BillingEventPublisher {
        sqs_publisher,
        user_uuid,
        db: db.clone(),
    };

    // Accumulate messages until completion or error
    while let Some(msg) = rx.recv().await {
        match accumulator.handle_message(msg) {
            AccumulatorState::Continue => continue,

            AccumulatorState::Complete(data) => {
                if let Err(e) = persister.persist_completed(data.clone()).await {
                    error!("Failed to persist completed response: {:?}", e);
                }
                billing.publish(data.prompt_tokens, data.completion_tokens).await;
                return;
            }

            AccumulatorState::Cancelled(data) => {
                if let Err(e) = persister.persist_cancelled(data).await {
                    error!("Failed to persist cancelled response: {:?}", e);
                }
                return;
            }

            AccumulatorState::Failed(data) => {
                error!("Storage task received error: {}", data.error);
                if let Err(e) = persister.persist_failed(data).await {
                    error!("Failed to persist failed response: {:?}", e);
                }
                return;
            }
        }
    }

    // Channel closed without Done or Error - treat as failure
    warn!("Storage channel closed before receiving Done signal");
    if let Err(e) = persister.persist_failed(FailureData {
        error: "Channel closed prematurely".to_string(),
        partial_content: String::new(),
        completion_tokens: 0,
    }).await {
        error!("Failed to persist incomplete response: {:?}", e);
    }
}
```

**Benefits:**
- Each component has a single responsibility
- Easy to unit test each component
- Clear state transitions
- Easier to add new completion states

---

### 游리 7. Authorization Middleware Pattern

**Location:** Repeated in every handler that needs conversation/response ownership check

**Problem:** Every handler repeats the same authorization + fetch + error mapping pattern.

**Solution:** Extract as reusable middleware that injects verified resources.

```rust
/// Middleware that verifies conversation ownership and injects it into extensions
async fn require_conversation_ownership(
    State(state): State<Arc<AppState>>,
    Path(conversation_id): Path<Uuid>,
    Extension(user): Extension<User>,
    mut req: Request,
    next: Next,
) -> Result<Response, ApiError> {
    let conversation = state
        .db
        .get_conversation_by_uuid_and_user(conversation_id, user.uuid)
        .map_err(|e| match e {
            DBError::ResponsesError(ResponsesError::ConversationNotFound) => ApiError::NotFound,
            _ => {
                error!("Failed to get conversation: {:?}", e);
                ApiError::InternalServerError
            }
        })?;

    req.extensions_mut().insert(conversation);
    Ok(next.run(req).await)
}

/// Middleware that verifies response ownership and injects it into extensions
async fn require_response_ownership(
    State(state): State<Arc<AppState>>,
    Path(response_id): Path<Uuid>,
    Extension(user): Extension<User>,
    mut req: Request,
    next: Next,
) -> Result<Response, ApiError> {
    let response = state
        .db
        .get_response_by_uuid_and_user(response_id, user.uuid)
        .map_err(|e| match e {
            DBError::ResponsesError(ResponsesError::ResponseNotFound) => ApiError::NotFound,
            DBError::ResponsesError(ResponsesError::Unauthorized) => ApiError::Unauthorized,
            _ => {
                error!("Failed to get response: {:?}", e);
                ApiError::InternalServerError
            }
        })?;

    req.extensions_mut().insert(response);
    Ok(next.run(req).await)
}

// Router configuration:
pub fn router(state: Arc<AppState>) -> Router {
    Router::new()
        .route(
            "/v1/conversations/:id",
            get(get_conversation)
                .layer(from_fn_with_state(state.clone(), require_conversation_ownership))
                .layer(from_fn_with_state(state.clone(), decrypt_request::<()>)),
        )
        .route(
            "/v1/responses/:id",
            get(get_response)
                .layer(from_fn_with_state(state.clone(), require_response_ownership))
                .layer(from_fn_with_state(state.clone(), decrypt_request::<()>)),
        )
        // ... other routes
        .with_state(state)
}

// Handlers become simpler:
async fn get_conversation(
    State(state): State<Arc<AppState>>,
    Extension(session_id): Extension<Uuid>,
    Extension(user): Extension<User>,
    Extension(conversation): Extension<Conversation>, // Injected by middleware!
) -> Result<Json<EncryptedResponse<ConversationResponse>>, ApiError> {
    // conversation already validated and fetched

    let user_key = state
        .get_user_key(user.uuid, None, None)
        .await
        .map_err(|_| ApiError::InternalServerError)?;

    let metadata = decrypt_metadata(&user_key, &conversation)?;

    let response = ConversationResponse {
        id: conversation.uuid,
        object: "conversation",
        metadata,
        created_at: conversation.created_at.timestamp(),
    };

    encrypt_response(&state, &session_id, &response).await
}
```

**Benefits:**
- DRY - no repeated authorization logic
- Handlers focus on business logic only
- Consistent error responses
- Easy to add authorization metrics

---

## Smaller High-Impact Changes

### 游리 8. Extract Common Response Building

**Location:** `src/web/responses.rs:982-1010, 1257-1303`

**Problem:** Near-identical `ResponsesCreateResponse` construction repeated multiple times.

**Solution:** Extract builder function.

```rust
fn build_response_object(
    response: &Response,
    status: &str,
    output: Vec<OutputItem>,
    usage: Option<ResponseUsage>,
    metadata: Option<Value>,
) -> ResponsesCreateResponse {
    ResponsesCreateResponse {
        id: response.uuid,
        object: "response",
        created_at: response.created_at.timestamp(),
        status,
        background: false,
        error: None,
        incomplete_details: None,
        instructions: None,
        max_output_tokens: response.max_output_tokens,
        max_tool_calls: None,
        model: response.model.clone(),
        output,
        parallel_tool_calls: response.parallel_tool_calls,
        previous_response_id: None,
        prompt_cache_key: None,
        reasoning: ReasoningInfo { effort: None, summary: None },
        safety_identifier: None,
        store: response.store,
        temperature: response.temperature.unwrap_or(1.0),
        text: TextFormat {
            format: TextFormatSpec {
                format_type: "text".to_string(),
            },
        },
        tool_choice: response.tool_choice.clone().unwrap_or_else(|| "auto".to_string()),
        tools: vec![],
        top_logprobs: 0,
        top_p: response.top_p.unwrap_or(1.0),
        truncation: "disabled",
        usage,
        user: None,
        metadata,
    }
}

// Usage:
let created_response = build_response_object(
    &response,
    "in_progress",
    vec![],
    None,
    decrypted_metadata.clone(),
);

let done_response = build_response_object(
    &response,
    "completed",
    vec![OutputItem { /* ... */ }],
    Some(usage),
    decrypted_metadata.clone(),
);
```

---

### 游릭 9. Use Builder Pattern for Complex Structs

**Problem:** Structs with many optional fields are verbose to construct.

**Solution:** Implement builder pattern.

```rust
impl ResponsesCreateResponse {
    fn builder(response: &Response) -> ResponsesCreateResponseBuilder {
        ResponsesCreateResponseBuilder::new(response)
    }
}

struct ResponsesCreateResponseBuilder {
    response: ResponsesCreateResponse,
}

impl ResponsesCreateResponseBuilder {
    fn new(response: &Response) -> Self {
        Self {
            response: ResponsesCreateResponse {
                id: response.uuid,
                object: "response",
                created_at: response.created_at.timestamp(),
                status: "in_progress",
                background: false,
                error: None,
                incomplete_details: None,
                instructions: None,
                max_output_tokens: response.max_output_tokens,
                max_tool_calls: None,
                model: response.model.clone(),
                output: vec![],
                parallel_tool_calls: response.parallel_tool_calls,
                previous_response_id: None,
                prompt_cache_key: None,
                reasoning: ReasoningInfo { effort: None, summary: None },
                safety_identifier: None,
                store: response.store,
                temperature: response.temperature.unwrap_or(1.0),
                text: TextFormat {
                    format: TextFormatSpec {
                        format_type: "text".to_string(),
                    },
                },
                tool_choice: response.tool_choice.clone().unwrap_or_else(|| "auto".to_string()),
                tools: vec![],
                top_logprobs: 0,
                top_p: response.top_p.unwrap_or(1.0),
                truncation: "disabled",
                usage: None,
                user: None,
                metadata: None,
            },
        }
    }

    fn status(mut self, status: &str) -> Self {
        self.response.status = status;
        self
    }

    fn output(mut self, output: Vec<OutputItem>) -> Self {
        self.response.output = output;
        self
    }

    fn usage(mut self, usage: ResponseUsage) -> Self {
        self.response.usage = Some(usage);
        self
    }

    fn metadata(mut self, metadata: Option<Value>) -> Self {
        self.response.metadata = metadata;
        self
    }

    fn build(self) -> ResponsesCreateResponse {
        self.response
    }
}

// Usage:
let created_response = ResponsesCreateResponse::builder(&response)
    .status("in_progress")
    .metadata(decrypted_metadata.clone())
    .build();

let done_response = ResponsesCreateResponse::builder(&response)
    .status("completed")
    .output(vec![output_item])
    .usage(usage)
    .metadata(decrypted_metadata)
    .build();
```

---

### 游리 10. Consolidate Error Mapping

**Location:** Repeated throughout both files

**Problem:** Similar error mapping patterns duplicated everywhere.

**Solution:** Extract error mapping helpers.

```rust
/// Centralized error mapping utilities
pub mod error_mapping {
    use crate::{db::DBError, models::responses::ResponsesError, ApiError};
    use tracing::error;

    pub fn map_conversation_error(e: DBError) -> ApiError {
        match e {
            DBError::ResponsesError(ResponsesError::ConversationNotFound) => ApiError::NotFound,
            _ => {
                error!("Conversation database error: {:?}", e);
                ApiError::InternalServerError
            }
        }
    }

    pub fn map_response_error(e: DBError) -> ApiError {
        match e {
            DBError::ResponsesError(ResponsesError::ResponseNotFound) => ApiError::NotFound,
            DBError::ResponsesError(ResponsesError::Unauthorized) => ApiError::Unauthorized,
            DBError::ResponsesError(ResponsesError::ValidationError) => ApiError::BadRequest,
            _ => {
                error!("Response database error: {:?}", e);
                ApiError::InternalServerError
            }
        }
    }

    pub fn map_message_error(e: DBError) -> ApiError {
        error!("Message database error: {:?}", e);
        ApiError::InternalServerError
    }

    pub fn map_generic_db_error(e: DBError) -> ApiError {
        error!("Database error: {:?}", e);
        ApiError::InternalServerError
    }
}

// Usage:
let conversation = state
    .db
    .get_conversation_by_uuid_and_user(conversation_id, user.uuid)
    .map_err(error_mapping::map_conversation_error)?;

let response = state
    .db
    .get_response_by_uuid_and_user(id, user.uuid)
    .map_err(error_mapping::map_response_error)?;
```

---

## Performance Optimizations

### 游릭 11. Pre-allocate Buffers with Capacity

**Location:** `src/web/responses.rs:824`

**Problem:** Buffer grows dynamically during SSE parsing.

**Solution:** Pre-allocate with estimated capacity.

```rust
// Before:
let mut buffer = String::new();

// After:
let mut buffer = String::with_capacity(8192); // Typical SSE frame size
```

**Impact:** Reduces allocations during streaming, especially for large responses.

---

### 游릭 12. Batch UUID Generation

**Location:** Multiple UUIDs generated sequentially

**Problem:** Multiple individual UUID generations.

**Solution:** Generate all needed UUIDs upfront.

```rust
// Before:
let assistant_message_id = Uuid::new_v4();
// ... later
let item_id = assistant_message_id.to_string();
// ... later
let another_id = Uuid::new_v4();

// After:
struct ResponseIds {
    assistant_message_id: Uuid,
    output_item_id: Uuid,
    content_part_id: Uuid,
}

impl ResponseIds {
    fn generate() -> Self {
        Self {
            assistant_message_id: Uuid::new_v4(),
            output_item_id: Uuid::new_v4(),
            content_part_id: Uuid::new_v4(),
        }
    }
}

let ids = ResponseIds::generate();
```

**Impact:** Minor, but improves code clarity and can optimize UUID generation if batched.

---

### 游릭 13. Reduce Metadata Cloning

**Location:** `src/web/responses.rs:1010, 1302`

**Problem:** `decrypted_metadata.clone()` called multiple times.

**Solution:** Use references or Arc.

```rust
// Before:
metadata: decrypted_metadata.clone(),
// ... later
metadata: decrypted_metadata.clone(),

// After: Keep one clone, reference it
let metadata = decrypted_metadata.clone();
// Use &metadata or Arc::new(metadata) depending on context
```

---

### 游릭 14. Early Token Counting

**Location:** `src/web/responses.rs:661-662`

**Problem:** Token counting happens after normalization and validation.

**Solution:** Count tokens during normalization to fail fast if needed.

```rust
impl InputMessage {
    pub fn normalize_with_token_count(self) -> (Vec<MessageInput>, i32) {
        let normalized = self.normalize();
        let text = MessageContentConverter::extract_text_for_token_counting(&normalized[0].content);
        let tokens = count_tokens(&text) as i32;
        (normalized, tokens)
    }
}

// Usage:
let (normalized_messages, user_message_tokens) = body.input.clone().normalize_with_token_count();
```

---

### 游리 15. Optimize Conversation Item Iteration

**Location:** `src/web/conversations.rs:651-730`

**Problem:** Multiple iterations over the same message list.

**Solution:** Process in a single pass where possible.

```rust
// Before: Multiple passes
for msg in raw_messages.iter() {
    trace!("Processing message: {}", msg.uuid);
}
for msg in raw_messages.iter().skip(start_index) {
    // Process again
}

// After: Single pass with state tracking
let mut items = Vec::with_capacity(raw_messages.len());
for (idx, msg) in raw_messages.iter().enumerate() {
    if idx < start_index {
        continue;
    }
    // Process once
}
```

---

## Architecture Improvements

### 游리 16. Separate Streaming Concerns from Business Logic

**Problem:** SSE streaming mechanics tightly coupled with response creation business logic.

**Solution:** Create a `StreamingResponseManager` that encapsulates streaming infrastructure.

```rust
pub struct StreamingResponseManager {
    state: Arc<AppState>,
    user: User,
    response: Response,
    conversation: Conversation,
    user_key: SecretKey,
}

impl StreamingResponseManager {
    pub fn new(
        state: Arc<AppState>,
        user: User,
        response: Response,
        conversation: Conversation,
        user_key: SecretKey,
    ) -> Self {
        Self {
            state,
            user,
            response,
            conversation,
            user_key,
        }
    }

    pub async fn stream_response(
        &self,
        chat_request: Value,
        headers: &HeaderMap,
    ) -> Result<Sse<impl Stream<...>>, ApiError> {
        // Setup channels
        let (tx_storage, rx_storage) = mpsc::channel(1024);
        let (tx_client, rx_client) = mpsc::channel(1024);

        // Spawn tasks
        self.spawn_storage_task(rx_storage).await;
        self.spawn_upstream_processor(tx_storage, tx_client, chat_request, headers).await?;

        // Create SSE stream
        Ok(self.create_sse_stream(rx_client))
    }

    async fn spawn_storage_task(&self, rx: mpsc::Receiver<StorageMessage>) {
        // ...
    }

    async fn spawn_upstream_processor(
        &self,
        tx_storage: mpsc::Sender<StorageMessage>,
        tx_client: mpsc::Sender<StorageMessage>,
        chat_request: Value,
        headers: &HeaderMap,
    ) -> Result<(), ApiError> {
        // ...
    }

    fn create_sse_stream(
        &self,
        mut rx_client: mpsc::Receiver<StorageMessage>,
    ) -> Sse<impl Stream<...>> {
        // ...
    }
}
```

**Benefits:**
- Clear separation of concerns
- Easier to test streaming logic independently
- Reusable for other streaming endpoints
- Encapsulates complexity

---

### 游리 17. Type-Safe Event System

**Problem:** String-based event types are error-prone.

**Solution:** Use enums for type safety.

```rust
#[derive(Debug, Clone, Serialize)]
#[serde(tag = "type")]
pub enum ResponseEvent {
    #[serde(rename = "response.created")]
    Created {
        sequence_number: i32,
        response: ResponsesCreateResponse,
    },

    #[serde(rename = "response.in_progress")]
    InProgress {
        sequence_number: i32,
        response: ResponsesCreateResponse,
    },

    #[serde(rename = "response.output_text.delta")]
    OutputTextDelta {
        sequence_number: i32,
        delta: String,
        item_id: String,
        output_index: i32,
        content_index: i32,
        logprobs: Vec<Value>,
    },

    #[serde(rename = "response.completed")]
    Completed {
        sequence_number: i32,
        response: ResponsesCreateResponse,
    },

    #[serde(rename = "response.cancelled")]
    Cancelled {
        id: String,
        created_at: i64,
        data: ResponseCancelledData,
    },

    #[serde(rename = "response.error")]
    Error {
        error: ResponseError,
    },

    // ... other event types
}

impl ResponseEvent {
    fn event_type(&self) -> &'static str {
        match self {
            ResponseEvent::Created { .. } => "response.created",
            ResponseEvent::InProgress { .. } => "response.in_progress",
            ResponseEvent::OutputTextDelta { .. } => "response.output_text.delta",
            ResponseEvent::Completed { .. } => "response.completed",
            ResponseEvent::Cancelled { .. } => "response.cancelled",
            ResponseEvent::Error { .. } => "response.error",
        }
    }

    async fn to_sse_event(&self, emitter: &mut SseEventEmitter) -> Event {
        emitter.emit(self.event_type(), self).await
    }
}

// Usage:
let event = ResponseEvent::Created {
    sequence_number: 0,
    response: created_response,
};
yield Ok(event.to_sse_event(&mut emitter).await);
```

**Benefits:**
- Compile-time verification of event structure
- Impossible to typo event type strings
- IDE autocomplete for event fields
- Easier refactoring

---

### 游릭 18. Extract Constants

**Problem:** Magic numbers and strings scattered throughout.

**Solution:** Centralize constants.

```rust
pub mod constants {
    /// Channel buffer sizes
    pub const STORAGE_CHANNEL_BUFFER: usize = 1024;
    pub const CLIENT_CHANNEL_BUFFER: usize = 1024;

    /// SSE buffer sizing
    pub const SSE_BUFFER_CAPACITY: usize = 8192;

    /// Default values
    pub const DEFAULT_TEMPERATURE: f32 = 0.7;
    pub const DEFAULT_TOP_P: f32 = 1.0;
    pub const DEFAULT_MAX_TOKENS: i32 = 10_000;

    /// Cost per token (in dollars)
    pub const COST_PER_TOKEN: &str = "0.0000053";

    /// Response object types
    pub const OBJECT_TYPE_RESPONSE: &str = "response";
    pub const OBJECT_TYPE_CONVERSATION: &str = "conversation";
    pub const OBJECT_TYPE_LIST: &str = "list";

    /// Event types
    pub const EVENT_RESPONSE_CREATED: &str = "response.created";
    pub const EVENT_RESPONSE_IN_PROGRESS: &str = "response.in_progress";
    pub const EVENT_RESPONSE_COMPLETED: &str = "response.completed";
    // ... etc
}
```

---

## Implementation Priority

Based on impact vs effort:

### Phase 1: Critical Foundation (Week 1)
1. 游댮 **Extract SSE Event Builder** (#2) - Eliminates 300+ lines of duplication
2. 游댮 **Extract Upstream Stream Processor** (#3) - Makes streaming logic testable
3. 游리 **Consolidate Error Mapping** (#10) - Quick win, improves consistency

### Phase 2: Core Refactorings (Week 2)
4. 游댮 **Break Up `create_response_stream`** (#1) - Biggest complexity reduction
5. 游댮 **Storage Task Separation** (#6) - Makes persistence logic testable
6. 游댮 **Centralize Message Conversions** (#4) - Eliminates scattered logic

### Phase 3: Developer Experience (Week 3)
7. 游리 **Authorization Middleware** (#7) - DRY improvement
8. 游리 **Decryption Helpers** (#5) - Type safety improvement
9. 游리 **Common Response Building** (#8) - Reduces duplication

### Phase 4: Polish & Optimization (Week 4)
10. 游리 **Type-Safe Event System** (#17) - Architecture improvement
11. 游릭 **Builder Patterns** (#9) - Nice to have
12. 游릭 **Performance Optimizations** (#11-15) - Minor wins

---

## Testing Strategy

After each refactoring:

1. **Unit Tests:**
   - Test each extracted component in isolation
   - Mock dependencies appropriately
   - Cover error cases

2. **Integration Tests:**
   - Verify end-to-end flow still works
   - Test SSE streaming completeness
   - Verify database persistence

3. **Manual Testing:**
   - Test with actual frontend client
   - Verify SSE events arrive correctly
   - Check database state after completion/cancellation

4. **Performance Testing:**
   - Benchmark before and after
   - Ensure no regressions
   - Measure memory usage

---

## Migration Strategy

For each refactoring:

1. **Extract New Code:**
   - Create new functions/structs alongside existing code
   - Keep old code working

2. **Add Tests:**
   - Write tests for new code
   - Ensure coverage before switching

3. **Switch Implementation:**
   - Replace old code with new code
   - Keep old code commented out temporarily

4. **Verify & Clean Up:**
   - Run full test suite
   - Manual testing
   - Remove old code once confident

5. **Document:**
   - Update relevant documentation
   - Add code comments where helpful

---

## Success Metrics

Track these metrics before and after refactoring:

- **Code Metrics:**
  - Lines of code per function (target: <200)
  - Cyclomatic complexity (target: <10)
  - Test coverage (target: >80%)

- **Performance Metrics:**
  - SSE event latency
  - Database query time
  - Memory usage per connection
  - Concurrent connection capacity

- **Developer Experience:**
  - Time to understand code for new contributors
  - Time to add new features
  - Bug rate in refactored areas

---

## Phase 5: Final Cleanup - Unused Code Analysis

### Overview

After the major refactorings, a clippy analysis revealed several "unused" warnings. Investigation showed that some items are actually used (but in different modules), some are reserved for future features (Conversations API), and some are genuinely unused dead code.

### 游댮 Critical: Use Missing Constants (HIGH PRIORITY)

These constants exist but hardcoded values are used instead. This breaks the "single source of truth" principle.

#### 1. Channel Buffer Sizes (handlers.rs:1043-1044)
**Current:**
```rust
let (tx_storage, rx_storage) = mpsc::channel::<StorageMessage>(1024);
let (tx_client, rx_client) = mpsc::channel::<StorageMessage>(1024);
```

**Should be:**
```rust
let (tx_storage, rx_storage) = mpsc::channel::<StorageMessage>(STORAGE_CHANNEL_BUFFER);
let (tx_client, rx_client) = mpsc::channel::<StorageMessage>(CLIENT_CHANNEL_BUFFER);
```

**Impact:** Medium - Centralizes buffer sizing configuration

---

#### 2. SSE Buffer Capacity (stream_processor.rs:33)
**Current:**
```rust
buffer: String::with_capacity(8192),
```

**Should be:**
```rust
buffer: String::with_capacity(SSE_BUFFER_CAPACITY),
```

**Impact:** Medium - Centralizes SSE buffer sizing

---

#### 3. Cost Per Token (storage.rs:297-300)
**Current:**
```rust
let input_cost = BigDecimal::from_str("0.0000053").unwrap() * BigDecimal::from(prompt_tokens);
let output_cost = BigDecimal::from_str("0.0000053").unwrap() * BigDecimal::from(completion_tokens);
```

**Should be:**
```rust
let input_cost = BigDecimal::from_str(COST_PER_TOKEN).unwrap() * BigDecimal::from(prompt_tokens);
let output_cost = BigDecimal::from_str(COST_PER_TOKEN).unwrap() * BigDecimal::from(completion_tokens);
```

**Impact:** HIGH - Centralized cost management for billing

---

#### 4. Default Request Parameters (handlers.rs:1023-1025)
**Current:**
```rust
"temperature": body.temperature.unwrap_or(0.7),
"top_p": body.top_p.unwrap_or(1.0),
"max_tokens": body.max_output_tokens.unwrap_or(10_000),
```

**Should be:**
```rust
"temperature": body.temperature.unwrap_or(DEFAULT_TEMPERATURE),
"top_p": body.top_p.unwrap_or(DEFAULT_TOP_P),
"max_tokens": body.max_output_tokens.unwrap_or(DEFAULT_MAX_TOKENS),
```

**Impact:** Medium - Centralized default values

---

#### 5. Object Type Constants (conversations.rs:408, 454, 514, 743, 942, 950)
**Current:**
```rust
object: "conversation",  // Hardcoded 6 times
object: "list",          // Hardcoded 2 times
```

**Should be:**
```rust
use crate::web::responses::constants::{OBJECT_TYPE_CONVERSATION, OBJECT_TYPE_LIST};

object: OBJECT_TYPE_CONVERSATION,
object: OBJECT_TYPE_LIST,
```

**Impact:** Medium - Consistency with responses module

---

#### 6. Role Constants (conversations.rs:678, 695, 823, 839)
**Current:**
```rust
role: "user".to_string(),      // Hardcoded multiple times
role: "assistant".to_string(),  // Hardcoded multiple times
```

**Should be:**
```rust
use crate::web::responses::constants::{ROLE_USER, ROLE_ASSISTANT};

role: ROLE_USER.to_string(),
role: ROLE_ASSISTANT.to_string(),
```

**Impact:** Medium - Consistency across codebase

---

#### 7. Duplicate Helper Function (conversations.rs:279)
**Current (DUPLICATE):**
```rust
// conversations.rs:279
fn assistant_text_to_content(text: String) -> Vec<ConversationContent> {
    vec![ConversationContent::OutputText { text }]
}
```

**Should be:**
```rust
// Remove local function, use centralized version:
use crate::web::responses::MessageContentConverter;

// Replace calls to assistant_text_to_content() with:
MessageContentConverter::assistant_text_to_content(text)
```

**Impact:** Medium - Eliminates code duplication

---

### 游릭 Keep for Future Use (Conversations API)

These are NOT unused - they're reserved for full Conversations API implementation:

8. **`to_conversation_content()`** - conversions.rs:106
   - Will be used when implementing full Conversations API item creation
   - Alternative to From trait for direct conversion

9. **`content_part_to_conversation()`** - conversions.rs:126
   - Helper for to_conversation_content()

**Recommendation:** KEEP - Mark with `#[allow(dead_code)]` until Conversations API is fully implemented

---

### 游딈勇 Remove Dead Code (Genuinely Unused)

#### 10. `map_encryption_error()` (errors.rs:98)
**Status:** Never used
**Reason:** Encryption errors handled inline in handlers
**Action:** REMOVE - Can be added back if needed
**Impact:** Low - cleanup only

---

#### 11. `set_sequence_number()` (events.rs:123)
**Status:** Never used
**Reason:** Sequence numbers are auto-managed, no need to manually set
**Action:** REMOVE - utility function not needed
**Impact:** Low - cleanup only

---

#### 12. `PreparedRequest.normalized_messages` (handlers.rs:607)
**Status:** Stored but never read
**Reason:** Only `message_content` is used after normalization
**Action:** REMOVE field from struct
**Impact:** Low - minor memory optimization

---

#### 13. `PersistedData.conversation` (handlers.rs:623)
**Status:** Stored but never read
**Reason:** Already available via `context.conversation`
**Action:** REMOVE field from struct, use `context.conversation` directly
**Impact:** Low - cleanup duplicate data

---

#### 14. `ContentAccumulator.finish_reason` (storage.rs:26)
**Status:** Stored but never read
**Reason:** Only used to pass through in Done message, not accessed by accumulator
**Action:** REMOVE field - not needed in accumulator state
**Impact:** Low - minor memory optimization

---

### 游닍 Adjust Module Visibility

These are exported as `pub` but only used internally within the responses module:

15. **`BillingEventPublisher`** (mod.rs:21)
16. **`ContentAccumulator`** (mod.rs:21)
17. **`ResponsePersister`** (mod.rs:21)

**Current:**
```rust
pub use storage::{storage_task, BillingEventPublisher, ContentAccumulator, ResponsePersister};
```

**Should be:**
```rust
// In storage.rs, change from pub to pub(crate):
pub(crate) struct BillingEventPublisher { ... }
pub(crate) struct ContentAccumulator { ... }
pub(crate) struct ResponsePersister { ... }

// In mod.rs, only export storage_task:
pub use storage::storage_task;
```

**Impact:** Low - Better encapsulation, cleaner public API

---

## Implementation Plan for Phase 5

### Step 1: Use Missing Constants (HIGH VALUE)
**Estimated time:** 30 minutes
**Risk:** Very low - simple find-and-replace

1. handlers.rs: Import and use buffer size constants
2. stream_processor.rs: Import and use SSE_BUFFER_CAPACITY
3. storage.rs: Import and use COST_PER_TOKEN
4. handlers.rs: Import and use default parameter constants
5. conversations.rs: Import and use OBJECT_TYPE_* and ROLE_* constants
6. conversations.rs: Remove duplicate assistant_text_to_content(), use MessageContentConverter

**Testing:** Full integration test suite + manual API testing

---

### Step 2: Clean Up Dead Code (CLEANUP)
**Estimated time:** 15 minutes
**Risk:** Very low - removing unused code

1. Remove `map_encryption_error()` from errors.rs
2. Remove `set_sequence_number()` from events.rs
3. Remove unused fields from PreparedRequest, PersistedData, ContentAccumulator

**Testing:** Cargo build + clippy

---

### Step 3: Fix Module Visibility (POLISH)
**Estimated time:** 10 minutes
**Risk:** Very low - internal change only

1. Change visibility to `pub(crate)` for internal-only types
2. Update mod.rs exports

**Testing:** Cargo build (will catch any external usage)

---

### Step 4: Document Future Use Items
**Estimated time:** 5 minutes
**Risk:** None - documentation only

Add `#[allow(dead_code)]` with explanatory comments:

```rust
// Reserved for full Conversations API implementation
#[allow(dead_code)]
pub fn to_conversation_content(
    content: MessageContent,
    role: &str,
) -> Vec<ConversationContent> {
    // ...
}
```

---

## Expected Outcomes

**After Phase 5 cleanup:**
- 九 Zero clippy warnings for unused code in responses module
- 九 All magic strings replaced with constants
- 九 No code duplication between modules
- 九 Cleaner public API surface
- 九 Better documentation of future-use code

**Lines of code impact:**
- handlers.rs: ~10 lines changed (constant usage)
- conversations.rs: ~15 lines changed (constant usage, remove duplicate)
- constants.rs: No changes (constants already exist!)
- errors.rs: -10 lines (remove unused function)
- events.rs: -5 lines (remove unused method)
- storage.rs: -1 line (remove unused field)
- **Net change:** ~-15 lines with better consistency

---

## Conclusion

These refactorings will significantly improve code maintainability while preserving the working functionality. Start with high-impact, low-risk changes (SSE event builder, error mapping) and progress to larger architectural improvements.

The key is to refactor incrementally, testing thoroughly after each change, and keeping the application working throughout the process.

**Phase 5 represents the final polish** - using all the centralized constants we created, eliminating true dead code, and ensuring a clean public API. This is low-risk, high-value work that makes the codebase more maintainable.